include.lowest = TRUE,
labels = c("Bajo", "Medio", "Alto"))
# checking results
table(perception2$p11_1r)
table(perception2$p11_2r)
perception2 <-  perception2 |>
dplyr::select(-p11_1, -p11_2)
fitord <- princals(perception2,
ordinal = T,
ndim = 3)  ## default is ordinal=TRUE
summary(fitord)
# CATPCA results: 46.2, 61.62, 71.12 (3 first components)
perception3 <- perception_vars
# Ideal quartile recoding
# First, we sort the data
p111_sorted <- sort(perception3$p11_1)
# Total number of observations
n <- length(p111_sorted)
# Compute j and h for ideal quartiles (Tukey's rule)
j <- round((n / 4) + (5 / 12))
h <- (n / 4) + (5 / 12) - j
# Calculate the ideal lower and upper quartiles
qi <- (1 - h) * p111_sorted[j] + h * p111_sorted[j + 1]
qs <- (1 - h) * p111_sorted[n - j + 1] + h * p111_sorted[n - j]
# Print the ideal quartile values
cat("Cuartil inferior (qi):", qi, "\n")
cat("Cuartil superior (qs):", qs, "\n")
# Recode the variable p11_1 using the ideal quartiles
perception3$p11_1r_recoded_ideal <- cut(perception3$p11_1,
breaks = c(min(perception3$p11_1), qi, qs, max(perception3$p11_1)),
include.lowest = TRUE,
labels = c("Bajo", "Medio", "Alto"))
# View the distribution of the new categories
table(perception3$p11_1r_recoded_ideal)
# Inspect values in each category
# Category "Low"
bajo_values <- subset(perception3, p11_1r_recoded_ideal == "Bajo")
summary(bajo_values$p11_1)
# Category "Medium"
medio_values <- subset(perception3, p11_1r_recoded_ideal == "Medio")
summary(medio_values$p11_1)
# Category "High"
alto_values <- subset(perception3, p11_1r_recoded_ideal == "Alto")
summary(alto_values$p11_1)
# Ideal quartile recoding
# First, we sort the data
p112_sorted <- sort(perception3$p11_2)
# Total number of observations
n <- length(p112_sorted)
# Compute j and h for ideal quartiles (Tukey's rule)
j <- round((n / 4) + (5 / 12))
h <- (n / 4) + (5 / 12) - j
# Calculate the ideal lower and upper quartiles
qi2 <- (1 - h) * p112_sorted[j] + h * p112_sorted[j + 1]
qs2 <- (1 - h) * p112_sorted[n - j + 1] + h * p112_sorted[n - j]
# Print the ideal quartile values
cat("Cuartil inferior (qi):", qi2, "\n")
cat("Cuartil superior (qs):", qs2, "\n")
# Recode the variable p11_2 using the ideal quartiles
perception3$p11_2r_recoded_ideal <- cut(perception3$p11_2,
breaks = c(min(perception3$p11_2), qi2, qs2, max(perception3$p11_2)),
include.lowest = TRUE,
labels = c("Bajo", "Medio", "Alto"))
# View the distribution of the new categories
table(perception3$p11_2r_recoded_ideal)
# Inspect values in each category
# Category "Low"
bajo_values <- subset(perception3, p11_2r_recoded_ideal == "Bajo")
summary(bajo_values$p11_2)
# Category "Medium"
medio_values <- subset(perception3, p11_2r_recoded_ideal == "Medio")
summary(medio_values$p11_2)
# Category "High"
alto_values <- subset(perception3, p11_2r_recoded_ideal == "Alto")
summary(alto_values$p11_2)
perception3 <-  perception3 |>
dplyr::select(-p11_1, -p11_2)
fitord <- princals(perception3,
ordinal = T,
ndim = 3)  ## default is ordinal=TRUE
summary(fitord)
# CATPCA results: 44.81, 60.76, 71.03 (3 first components)
rm(perception2)
# Quartile based encoding
perception2 <- perception_vars
perception2$p11_1r <- cut(perception2$p11_1,
breaks = quantile(perception2$p11_1, probs = 0:3 / 3),
include.lowest = TRUE,
labels = c("Bajo", "Medio", "Alto"))
perception2$p11_2r <- cut(perception2$p11_2,
breaks = quantile(perception2$p11_2, probs = 0:3 / 3),
include.lowest = TRUE,
labels = c("Bajo", "Medio", "Alto"))
# checking results
table(perception2$p11_1r)
table(perception2$p11_2r)
fitord <- princals(perception2,
ordinal = T,
ndim = 3)  ## default is ordinal = TRUE
summary(fitord)
# Checking component loadings
fitord$loadings
# Loadings plot or biplot
plot(fitord, "loadplot",
main = "Loadings Plot ABC Data")  ## aspect ratio = 1
# Screeplot
plot(fitord, "screeplot")
# Extract component scores.
component_scores <- fitord$objects[, 1:2]
# Rename columns for clarity.
colnames(component_scores) <- c("gen_ins", "inst_ins")
# Add to pamplonaf
pamplonaf <- cbind(pamplonaf, component_scores)
# pamplonaf <- pamplonaf |> dplyr::select(-gen_ins, -inst_ins)
pampre <- pamplonaf |>
dplyr::select(-p5_1, -p5_2, -p5_3,
-p5_4, -p5_5, -p5_6,
-p5_7, -p5_8,
-p6_1, -p6_2, -p6_3,
-p7_2, -p7_3,
-p7_4, -p7_5, -p7_6,
-p10_1, -p10_2,
-p11_1, -p11_2) |>
mutate(crime_index = as.numeric(crime_index))
cor(pampre[, c("gen_ins", "inst_ins")], use = "complete.obs")
# recoding INCOME, EDUCATION, EMPLOYMENT to reduce the number of categories
pampre <- pampre |>
# EDUCATION: categories 3 and 4 are both secundary education, collapsed into one cat.
mutate(education = case_when(education %in% c("1", "2") ~ "1",
education %in% c("3", "4") ~ "2",
education == "5" ~ "3",
TRUE ~ education  # Keep all other values unchanged
)) |>
mutate(education = as.ordered(education))
pampre <- pampre |>
# EMPLOYMENT: categories 3 and 4 are both secundary employment, collapsed into one cat.
mutate(employment = case_when(employment %in% c("1", "2") ~ "1",
employment %in% c("3", "4") ~ "2",
employment %in% c("6", "7", "8") ~ "3",
TRUE ~ employment  # Keep all other values unchanged
)) |>
mutate(employment = as.ordered(employment))
pampre <- pampre |>
# INCOME
mutate(income = case_when(income %in% c("1", "2") ~ "1",
income %in% c("3", "4") ~ "2",
income %in% c("5", "6", "7") ~ "3",
income %in% c("8", "9", "10") ~ "4",
TRUE ~ income  # Keep all other values unchanged
)) |>
mutate(income = as.ordered(income))
# Combine neighborhoods 8 and 9
p13_comb <- pampre %>%
mutate(
barrio = case_when(
barrio %in% c("8", "9") ~ "8",
barrio == "10" ~ "9",
barrio == "11" ~ "10",
barrio == "12" ~ "11",
barrio == "13" ~ "12",
barrio == "14" ~ "13",
TRUE ~ barrio),
p13a = case_when(p13a %in% c("8", "9") ~ "8",
p13a == "10" ~ "9",
p13a == "11" ~ "10",
p13a == "12" ~ "11",
p13a == "13" ~ "12",
p13a == "14" ~ "13",
TRUE ~ p13a),
p13b = case_when(p13b %in% c("8", "9") ~ "8",
p13b == "10" ~ "9",
p13b == "11" ~ "10",
p13b == "12" ~ "11",
p13b == "13" ~ "12",
p13b == "14" ~ "13",
TRUE ~ p13b),
barrio = factor(barrio, levels = as.character(1:13)),
p13a = factor(p13a, levels = as.character(1:13)),
p13b = factor(p13b, levels = as.character(1:13)))
# Converting ordinal variables to ordered factors
make_ordered <- function(data, vars) {
for (var in vars) {
data[[var]] <- as.ordered(data[[var]])
}
return(data)
}
pampre <- make_ordered(pampre, c("p7_1", "p7_7", "p7_8",
"p10_3", "p10_4", "p10_5", "p10_6", "p10_7",
"p12", "p15", "p19",
"employment", "education", "income",
"victimized"))
# Re-encodes binary variables to 0/1. This recodes 1 to 1 and 2 to 0, so maybe consider changing this
recode_binary <- function(data, vars, value_to_keep = 1, new_value = 1, other_value = 0) {
for (var in vars) {
data[[var]] <- ifelse(data[[var]] == value_to_keep, new_value, other_value)
}
return(data)
}
pampre <- recode_binary(pampre, c("gender", "nationality",
"p8", "p9","p16"))
# Standardizes numeric variables using Z-scores
pampre$crime_index_z <- scale(pampre$crime_index)
pampre$agez <- scale(pampre$age)
pampre$agez <- as.numeric(pampre$agez)
pampre$p14z <- scale(pampre$p14) # es una escala del 1 al 10 pero como no la trato como ordinal (no sé si debería, la trato como numérica y la escalo)
pampre$gen_ins1 <- scale(pampre$gen_ins)
pampre$gen_ins1 <- as.numeric(pampre$gen_ins1)
# Cleaning up the dataset by removing unstandardized columns
pampre <- pampre |>
dplyr::select(-crime_index, -p14)
modelo_mv <- lm(cbind(gen_ins1, inst_ins) ~ agez + gender + education + income + employment + nationality + barrio, data = pampre)
# Wilks & Pillai tests are robust and measure if there is a significant global effect. If it is, individual effects can be assessed.
summary(manova(modelo_mv), test = "Wilks")
summary(manova(modelo_mv), test = "Pillai")
summary(modelo_mv)
modelo_mv <- lm(cbind(gen_ins, inst_ins) ~ agez + gender + education + income + employment + nationality + barrio + victimized + p10_3 + p12 + p15 + p16 + p13a + p13b + p18 + p19 + p14z + p7_7 + p8 + p9, data = pampre)
summary(modelo_mv)
# Final theoretical adjusted model
modelo_mv <- lm(cbind(gen_ins, inst_ins) ~ agez + gender + education + income + employment + nationality + barrio + victimized + p7_1 + p7_8 + p10_3 + p10_4 + p10_5 + p10_6 + p12 + p15 + p16 + p13a + p13b + p18 + p19 + p14z + p7_7 + p8 + p9, data = pampre)
summary(modelo_mv)
# Model formula for gen_ins
form_gen <- gen_ins ~ agez + gender + education + income + employment + nationality + barrio + victimized + p7_1 + p7_8 + p10_3 + p10_4 + p10_5 + p10_6 + p12 + p15 + p16 + p13a + p13b + p18 + p19 + p14z + p7_7 + p8 + p9
# Store original model matrix columns
original_gen <- lm(form_gen, data = pampre)
ols_step_forward_p(original_gen) # adj R2 0.503. 19 vars. gender included
ols_step_forward_aic(original_gen) # adj R2 0.497. 14 vars. gender included
ols_step_backward_aic(original_gen) # adj R2 0.50. 10 vars. gender NOT included
# Model formula for inst_ins
form_inst <- inst_ins ~ agez + gender + education + income + employment + nationality + barrio + victimized + p7_1 + p7_8 + p10_3 + p10_4 + p10_5 + p10_6 + p12 + p15 + p16 + p13a + p13b + p18 + p19 + p14z + p7_7 + p8 + p9
# Store original model matrix columns
original_inst <- lm(form_inst, data = pampre)
ols_step_forward_p(original_inst) #  adj R2 0.188. 11 vars. gender included
ols_step_forward_aic(original_inst) #  adj R2 0.188 11 vars. gender included
ols_step_backward_aic(original_inst) #  adj R2 0.188 14 vars. gender NOT included
# Function to identify rare levels in all factor/character variables
get_rare_levels <- function(data, threshold = 2) {
rare_levels <- list()
for (var in names(data)) {
if (is.factor(data[[var]]) || is.character(data[[var]])) {
level_counts <- table(data[[var]])
rare <- names(level_counts[level_counts <= threshold])
if (length(rare) > 0) {
rare_levels[[var]] <- rare
}
}
}
return(rare_levels)
}
# Identifying rare levels
rare_levels_full <- get_rare_levels(pampre, threshold = 2)
# Delete rows with rare levels
rows_to_keep <- rep(TRUE, nrow(pampre))
for (var in names(rare_levels_full)) {
rows_to_keep <- rows_to_keep & !(pampre[[var]] %in% rare_levels_full[[var]])
}
pampre_filtered <- pampre[rows_to_keep, ]
# Deleting categories with rare levels
pampre_filtered[] <- lapply(pampre_filtered, function(x) {
if (is.factor(x)) droplevels(x) else x
})
# Function to verify empty levels in the test
get_empty_levels <- function(train, test) {
vars <- names(train)
empty_in_test <- list()
for (var in vars) {
if (is.factor(train[[var]])) {
test_levels <- unique(test[[var]])
missing <- setdiff(levels(train[[var]]), test_levels)
if (length(missing) > 0) {
empty_in_test[[var]] <- missing
}
}
}
return(empty_in_test)
}
repeat_split <- function(data, response, p = 0.80, max_tries = 100, seed = 123) {
set.seed(seed)  # Setting an external seed to ensure reproducibility
for (i in 1:max_tries) {
current_seed <- seed + i
set.seed(current_seed)
in_train <- createDataPartition(data[[response]], p = p, list = FALSE)
train <- data[in_train, ]
test  <- data[-in_train, ]
missing_levels <- get_empty_levels(train, test)
if (length(missing_levels) == 0) {
message("✅ Successful split on try ", i, " (seed = ", current_seed, ")")
return(list(train = train, test = test, seed = current_seed, attempt = i))
}
}
stop("❌ Could not create a balanced split after ", max_tries, " attempts.")
}
# Fixed seed
split_result <- repeat_split(pampre_filtered, response = "gen_ins", seed = 456)
training <- split_result$train
testing  <- split_result$test
get_empty_levels(training, testing)
set.seed(123)
# CV control
ctrl <- trainControl(method = "repeatedcv", number = 5, repeats = 3)
# gen_ins models
model_gen_full <- gen_ins ~ agez + gender + education + income + employment + nationality + barrio + victimized + p7_1 + p7_8 + p10_3 + p10_4 + p10_5 + p10_6 + p12 + p15 + p16 + p13a + p13b + p18 + p19 + p14z + p7_7 + p8 + p9
model_gen_forward <- gen_ins ~ agez + gender  + income + nationality + employment + victimized + p7_1 + p7_8 + p10_3 + p10_4 + p10_6 + p12 + p15 + p16 + p13a + p13b + p14z + p7_7 + p8 + p9
# inst_ins models
model_inst_full = inst_ins ~ agez + gender + education + income + employment + nationality + barrio + victimized + p7_1 + p7_8 + p10_3 + p10_4 + p10_5 + p10_6 + p12 + p15 + p16 + p13a + p13b + p18 + p19 + p14z + p7_7 + p8 + p9
model_inst_forward <- inst_ins ~ agez + gender  + income + nationality + employment + victimized + p7_1 + p7_8 + p10_3 + p10_4 + p10_6 + p12 + p15 + p16 + p13a + p13b + p14z + p7_7 + p8 + p9
# Training the models
gen_model_full     <- train(model_gen_full, data = training, method = "lm", trControl = ctrl, preProc = c("center", "scale", "zv"))
gen_model_forward  <- train(model_gen_forward, data = training, method = "lm", trControl = ctrl, preProc = c("center", "scale", "zv"))
inst_model_full    <- train(model_inst_full, data = training, method = "lm", trControl = ctrl, preProc = c("center", "scale", "zv"))
inst_model_forward <- train(model_inst_forward, data = training, method = "lm", trControl = ctrl, preProc = c("center", "scale", "zv"))
# Predictions
test_results <- data.frame(
gen_ins  = testing$gen_ins,
inst_ins = testing$inst_ins
)
test_results$gen_pred_full     <- predict(gen_model_full, testing)
test_results$gen_pred_forward  <- predict(gen_model_forward, testing)
test_results$inst_pred_full    <- predict(inst_model_full, testing)
test_results$inst_pred_forward <- predict(inst_model_forward, testing)
# Testing the model
gen_full_perf     <- postResample(test_results$gen_pred_full,     test_results$gen_ins)
gen_forward_perf  <- postResample(test_results$gen_pred_forward,  test_results$gen_ins)
inst_full_perf    <- postResample(test_results$inst_pred_full,    test_results$inst_ins)
inst_forward_perf <- postResample(test_results$inst_pred_forward, test_results$inst_ins)
# DF with results
results_table <- data.frame(
Model = c("gen_full", "gen_forward", "inst_full", "inst_forward"),
RMSE = c(gen_full_perf["RMSE"], gen_forward_perf["RMSE"],
inst_full_perf["RMSE"], inst_forward_perf["RMSE"]),
Rsquared = c(gen_full_perf["Rsquared"], gen_forward_perf["Rsquared"],
inst_full_perf["Rsquared"], inst_forward_perf["Rsquared"]),
MAE = c(gen_full_perf["MAE"], gen_forward_perf["MAE"],
inst_full_perf["MAE"], inst_forward_perf["MAE"])
)
print(results_table)
modelo_mv <- lm(cbind(gen_ins, inst_ins) ~ agez + gender  + income + nationality + employment + victimized + p7_1 + p7_8 + p10_3 + p10_4 + p10_6 + p12 + p15 + p16 + p13a  + p14z + p7_7 + p8 + p9 + p13a*gender + p10_3*barrio + p7_7*p14z, data = pampre) # este modelo es incluso mejor que el de antes.
summary(modelo_mv)
# Wilks & Pillai tests are robust and measure if there is a significant global effect. If it is, individual effects can be assessed.
summary(manova(modelo_mv), test = "Wilks")
summary(manova(modelo_mv), test = "Pillai")
summary(modelo_mv)
# multicollinearity
car::vif(lm(gen_ins ~ agez + gender + education + income + employment + nationality + barrio + victimized + p7_1 + p7_8 + p10_3 + p10_4 + p10_5 + p10_6 + p12 + p15 + p16 + p13a + p13b + p18 + p19 + p14z + p7_7 + p8 + p9, data = pampre))
# residual distribution
MVN::mvn(residuals(modelo_mv),
mvnTest = "royston")
# Get robust standard errors
coeftest(modelo_mv,
vcov = vcovHC(modelo_mv, type = "HC1"))
library(boot)
# Define model formula
form_gen <- gen_ins ~ agez + gender + education + income + employment + nationality + barrio +
victimized + p7_1 + p7_8 + p10_3 + p10_4 + p10_5 + p10_6 +
p12 + p15 + p16 + p13a + p13b + p18 + p19 + p14z + p7_7 + p8 + p9
# Store original model matrix columns
original_fit <- lm(form_gen, data = pampre)
coef_names <- names(coef(original_fit))
# Bootstrap function
boot_fn <- function(data, indices) {
d <- data[indices, ]
fit <- try(lm(form_gen, data = d), silent = TRUE)
if (inherits(fit, "try-error")) {
return(rep(NA, length(coef_names)))  # Fill with NAs if it breaks
}
coefs <- coef(fit)
full_coefs <- setNames(rep(NA, length(coef_names)), coef_names)
full_coefs[names(coefs)] <- coefs
return(full_coefs)
}
# Run bootstrap
set.seed(123)
results <- boot(data = pampre, statistic = boot_fn, R = 5000)
# Check names to confirm index
names(results$t0)
# Get bootstrap CI for gender (or any other variable)
boot.ci(results, type = "perc", index = which(names(results$t0) == "gender"))
# esta es la mejor combinación de group_by. todas las demás que he probado generaban alguna variable que no coincidia con la distirbución original. igualmente, age va fatal... pero es necesaria para el segundo componente; en caso de que trabaje solo con el primero, la elimino.
set.seed(123)  # Set seed for reproducibility
# Prepare a sample of agents from the survey data
agents <- pampre %>%
mutate(p14z = as.numeric(p14z)) |>
dplyr::select(gender, age, income, employment,
nationality, victimized, barrio, gen_ins,
p7_1, p7_8, p10_3, p10_4, p10_5, p10_6, p12,
p15, p16, p13a, p13b, p18, p19, p7_7, p8, p9) |>
mutate(age_group = cut(age,  # Create age group categories
breaks = c(0, 30, 50, Inf),
labels = c("young", "middle", "senior"),
right = FALSE)) |>
group_by(age_group, barrio) %>%  # Stratify by age group and neighborhood
sample_frac(0.2) |>  # Sample 20% of each group
ungroup() |>
dplyr::mutate(barrio_res = case_when(  # Replace barrio IDs with descriptive names
barrio == "1" ~ "Iturrama",
barrio == "2" ~ "San Juan/Donibane",
barrio == "3" ~ "Casco Viejo/Alde Zaharra",
barrio == "4" ~ "Ensanche/Zabalgunea",
barrio == "5" ~ "Milagrosa-Arrosadia",
barrio == "6" ~ "Rochapea/Arrotxapea",
barrio == "7" ~ "Mendillorri",
barrio %in% c("8", "9") ~ "Ermitagaña-Mendebaldea",
barrio == "10" ~ "San Jorge-Sanduzelai",
barrio == "11" ~ "Txantrea",
barrio == "12" ~ "Etxabakoitz",
barrio == "13" ~ "Lezkairu",
barrio == "14" ~ "Buztintxuri-Euntzetxiki"
),
barrio_res = as.factor(barrio_res)) |>
dplyr::select(-age_group, -barrio)
# Final clean-up
agents_clean <- agents
rownames(agents_clean) <- NULL  # Remove row names
agents_clean <- as.data.frame(agents_clean, stringsAsFactors = FALSE)
colnames(agents_clean)  # Check column names
# Export to CSV, ready to use in GAMA
readr::write_csv(agents_clean, "gama_agents1.csv")
# Reading the shapefile containing neighborhood boundaries
shp <- st_read("URBA_Pol_Barrios/URBA_Pol_Barrios.shp")
# Creating a new grouping variable to merge selected neighborhoods
shp <- shp |>
mutate(grupo = if_else(ID %in% c(0, 9),
"fusionado",
as.character(ID)))
# Group by the new variable and merge geometries, keeping relevant attributes
shp_union <- shp |>
group_by(grupo) |>
summarise(across(where(~!inherits(.x, "sfc")), first),
.groups = "drop",
geometry = st_union(geometry))
# Keeping the rest of the shapefile and merge it with the new grouped area
shp_rest <- shp[!shp$ID %in% c(0, 9), ]
shp_final <- rbind(shp_rest, shp_union) |>
distinct(ID,
.keep_all = T) |>
arrange(ID) |>
mutate(BARRIO = case_when(BARRIO == "Azpilagaña" ~ "Milagrosa-Arrosadia",
TRUE ~ BARRIO)) |>
dplyr::select(-grupo)
# Saving the updated shapefile with the merged neighborhood, ready to use in GAMA
st_write(shp_final, "pamplona_barrios.shp")
# Creating a tibble for all categories
categorias <- tibble(p13b = factor(as.character(1:13),
levels = as.character(1:13)))
categorias1 <- tibble(p13a = factor(as.character(1:13),
levels = as.character(1:13)))
# Counting data
count_unsafe <- p13_comb %>%
dplyr::select(p13b) %>%
group_by(p13b) %>%
summarise(casos_p13b = n(), .groups = "drop")
count_safe <- p13_comb %>%
dplyr::select(p13a) %>%
group_by(p13a) %>%
summarise(casos_p13a = n(), .groups = "drop")
# Left_join to ensure all categories are present
votes_unsafe <- categorias %>%
left_join(count_unsafe, by = "p13b") %>%
mutate(casos_p13b = replace_na(casos_p13b, 0)) %>%
arrange(p13b) |> pull()
# Paso 3: hacer left_join para asegurar todas las categorías estén presentes
votes_safe <- categorias1 %>%
left_join(count_safe, by = "p13a") %>%
mutate(casos_p13a = replace_na(casos_p13a, 0)) %>%
arrange(p13a) |> pull()
# Normalize by total responses (or use raw counts if sample size constant)
total_votes_safe <- sum(votes_safe)
total_votes_unsafe <- sum(votes_unsafe)
safe_prop <- votes_safe / total_votes_safe
unsafe_prop <- votes_unsafe / total_votes_unsafe
# Composite score: higher = safer
composite_score <- safe_prop - unsafe_prop
# Create data frame for mapping
barrio_scores <- data.frame(
barrio_id = 1:13,
votes_safe = votes_safe,
votes_unsafe = votes_unsafe,
safe_prop = safe_prop,
unsafe_prop = unsafe_prop,
safety_score = composite_score
)
modelo_mv <- lm(cbind(gen_ins1, inst_ins) ~ agez + gender + education + income + employment + nationality + barrio, data = pampre)
# Wilks & Pillai tests are robust and measure if there is a significant global effect. If it is, individual effects can be assessed.
summary(manova(modelo_mv), test = "Wilks")
summary(manova(modelo_mv), test = "Pillai")
summary(modelo_mv)
gen_full_perf
gen_full_perf
gen_forward_perf
inst_full_perf
inst_forward_perf
model_gen_forward <- gen_ins ~ agez + gender  + income + nationality + employment + victimized + p7_1 + p7_8 + p10_3 + p10_4 + p10_6 + p12 + p15 + p16 + p13a  + p14z + p7_7 + p8 + p9 + p13a*gender + p10_3*barrio + p7_7*p14z
gen_model_forward  <- train(model_gen_forward, data = training, method = "lm", trControl = ctrl, preProc = c("center", "scale", "zv"))
model_inst_forward <- inst_ins ~ agez + gender  + income + nationality + employment + victimized + p7_1 + p7_8 + p10_3 + p10_4 + p10_6 + p12 + p15 + p16 + p13a  + p14z + p7_7 + p8 + p9 + p13a*gender + p10_3*barrio + p7_7*p14z
inst_model_forward <- train(model_inst_forward, data = training, method = "lm", trControl = ctrl, preProc = c("center", "scale", "zv"))
# Predictions
test_results <- data.frame(
gen_ins  = testing$gen_ins,
inst_ins = testing$inst_ins
)
test_results$gen_pred_full     <- predict(gen_model_full, testing)
test_results$gen_pred_forward  <- predict(gen_model_forward, testing)
test_results$inst_pred_full    <- predict(inst_model_full, testing)
test_results$inst_pred_forward <- predict(inst_model_forward, testing)
# Testing the model
gen_full_perf     <- postResample(test_results$gen_pred_full,     test_results$gen_ins)
gen_forward_perf  <- postResample(test_results$gen_pred_forward,  test_results$gen_ins)
inst_full_perf    <- postResample(test_results$inst_pred_full,    test_results$inst_ins)
inst_forward_perf <- postResample(test_results$inst_pred_forward, test_results$inst_ins)
inst_forward_perf
gen_forward_perf
modelo_mv <- lm(cbind(gen_ins, inst_ins) ~ agez + gender  + income + nationality + employment + victimized + p7_1 + p7_8 + p10_3 + p10_4 + p10_6 + p12 + p15 + p16 + p13a  + p14z + p7_7 + p8 + p9, data = pampre) # este modelo es incluso mejor que el de antes, pero si lo paso por CV es peor... asi q mejor me quedo como estoy + p13a*gender + p10_3*barrio + p7_7*p14z
summary(modelo_mv)
