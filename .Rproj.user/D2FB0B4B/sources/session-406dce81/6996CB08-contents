---
title: "THESIS"
output: html_document
date: "2024-06-24"
editor_options: 
  markdown: 
    wrap: 72
---

Dudas:

The data imbalance you've observed, where the "yes" category
(representing incidents or perceptions of crime) is underrepresented,
can pose challenges in your analysis, particularly in the context of
creating an objective crime index. This imbalance can lead to biased
models and incorrect interpretations if not addressed properly. Here are
the key issues and potential solutions:

Issues with Data Imbalance 1. Biased Models: Machine learning models can
become biased towards the majority class ("no" responses) because they
are overrepresented. This can result in poor predictive performance for
the minority class ("yes" responses), which is often the more critical
class in this context.

2.  Misleading Metrics: Metrics such as accuracy can be misleading in
    imbalanced datasets. For example, a model that predicts the majority
    class for every observation would still achieve a high accuracy,
    despite failing to correctly predict the minority class.

3.  Limited Information on Minority Class: The underrepresentation of
    "yes" responses can lead to insufficient data to learn patterns or
    correlations for this class, which may be crucial for your index.

Applying resampling techniques to all imbalanced variables can be
useful, but it depends on the specific goals of your analysis and the
nature of each variable. Here are some considerations to help you
decide:

1.  Nature of the Variables and Their Role in the Index Critical
    Variables: If certain variables are critical for the calculation of
    your objective crime index (e.g., direct indicators of crime like
    incidents of theft, violence), ensuring these are well-represented
    in the dataset is essential. Resampling these variables can help
    improve the model's understanding and predictions regarding the
    occurrence of these incidents.

Auxiliary Variables: For variables that provide supplementary
information but are not central to the index, resampling may not be as
crucial. The impact of these variables on the overall index may be
limited, and excessive resampling could introduce noise or overfitting.

2.  Impact of Resampling on Analysis Dimensionality and Model
    Complexity: Over-resampling all variables can increase the dataset
    size significantly and may lead to overfitting, especially if the
    dataset becomes dominated by synthetic data. It can also make the
    model more complex and harder to interpret.

Specific Analysis Requirements: If your analysis includes feature
importance evaluation or building a predictive model, ensuring that key
predictors are balanced might be more critical than balancing all
variables. However, if the analysis focuses on descriptive statistics or
correlations, the need for resampling may be less pressing.

3.  Evaluating the Imbalance's Impact Data Distribution Check: Evaluate
    the distribution of the minority class in each variable. If some
    variables have extremely low minority representation (e.g., less
    than 1%), they might need more aggressive resampling or specialized
    techniques like anomaly detection.

Model Performance Metrics: Experiment with and without resampling for
different variables and compare the performance metrics (e.g.,
precision, recall, F1-score) for each approach. This can provide insight
into whether resampling is necessary for all variables or just a subset.

4.  Practical Approach Prioritize Key Variables: Start with resampling
    techniques for the most critical variables directly related to crime
    incidents (e.g., P5 and P6 variables). Evaluate the model's
    performance and the resulting index's reliability.

Selective Resampling: If the initial results suggest that other
imbalanced variables are influencing the index significantly, consider
resampling those as well. This selective approach can help balance the
need for comprehensive data representation with the risks of overfitting
and increased complexity.

Iterative Process: Treat this as an iterative process. Begin with a base
model and progressively include resampling for additional variables as
needed, based on model evaluation and index stability.

1.  **IMPUTACIÓN NA**. No sé si he hecho la imputación bien. La base de
    datos tiene variables binarias, ordinales, categóricas de varias
    categorías y numéricas (discretas). He intentado aplicar al menos
    dos métodos de imputación para cada tipo de variable para comparar
    cuál funcionaba mejor, pero me daba error. Al parecer cada método
    necesita trabajar con el mismo tipo de variables porque si no puede
    dar error. Finalmente decidí usar cart (que vale para todo tipo de
    variables) porque no tengo ese problema.

    Para validar los resultados ya que no puedo comparar las
    distribuciones resultantes de diferentes métodos de imputación con
    la distribución original, apliqué cart con una sola variable de cada
    tipo (categórica y numérica) usando cross validation y comparé la
    distribución resultante con la distribución original. Después,
    apliqué cart directamente a toda la base de datos (sin cross
    validation)

    **Debería hacer la imputación final usando cross validation**? El
    problema es que me multiplicaba la base de datos y no era capaz de
    reducirla al número de observaciones originales (cosa que sí pude
    hacer con una sola variable cuando estaba testeando cart
    normalizando los datos para corregir las diferencias en el tamaño de
    la muestra). En principio creo que debería ser suficiente así...

The visual difference in bar heights is due to the different number of
observations rather than a change in the relative distribution of
categories. The proportions are consistent between the original and
imputed datasets, as indicated by the quantitative data you provided.
Normalizing the Data for Comparison To make a proper visual comparison,
you should normalize the frequency counts to proportions (relative
frequencies) instead of raw counts. This adjustment will make it easier
to compare the distributions, regardless of the total number of
observations in each dataset. - Normalized plot comparison

-   Uso de unsupervised machine learning (si) y supervised machine
    learning (no).

<!-- -->

-   **ÍNDICE DE CRIMINALIDAD OBJETIVA**:

    1.  Data imbalance.

    2.  Encontré un balance anual de infracciones penales registradas en
        Pamplona para el año 2022 (año de la encuesta), publicada por el
        ministerio del interior, pero aparecen los datos totales, no he
        conseguido encontrarlos por barrio (ni aquí, ni en ningún otro
        sitio). Me habría gustado mucho hacer el índice por barrios como
        comentamos para hacerlo más accurate y poder hacer una
        comparativa por zonas de la ciudad, pero no tengo los datos
        oficiales.
        ![](images/Captura%20de%20pantalla%202024-07-29%20a%20las%200.56.51.png){width="539"}

        Sobre la info que recoge la encuesta, aunque sí pregunta por
        situaciones que se hayan vivido, no pregunta por el barrio en el
        que ocurrió (el barrio, en realidad, solo se menciona para
        preguntar por cómo de seguro se siente allí en general y por la
        noche solo, y para saber dónde se reside, y alguna pregunta más
        del estilo).

        Lo que he hecho entonces ha sido coger esta tabla, quedarme sólo
        con criminalidad convencional y agrupar los delitos por
        categorías similares a las que incluye la base de datos de la
        encuesta. Lo dejé ahí porque son datos que creo que
        enriquecerían el modelo, pero no sé muy bien cómo incluir las
        observaciones? porque son para toda la población, entonces
        debería hacer como una proporción de cuánta gente la ha
        sufrido...? no sé cómo hacerlo.

-   **ÍNDICE DE PERCEPCIÓN DE LA INSEGURIDAD**.

    -   PCA

-   Tipos de zona

```{r}
library(tidyverse)  # Conjunto de paquetes para manipulación de datos
library(skimr)      # Paquete para análisis exploratorio
library(DataExplorer)  # Paquete para análisis exploratorio visual
library(labelled)
library(stringr)
library(dplyr)
library(tidyr)
library(forcats)

library(haven)
library(memisc) #dezcription function
library(DataExplorer)
library(caret) 
library(FactoMineR)
library(factoextra)
library(mice)
library(missMDA)
library(cowplot)
library(cv)

library(janitor)  # For tabyl function
library(pdftools)


```

```{r}
# Survey and crime data
pamplona_spss <- as.data.frame(read_sav("23-085 - Ayuntamiento de Navarra (SPSS01).sav"))
delitos <- pdf_text("Balance-de-Criminalidad-Cuarto-Trimestre-2022.pdf")[462]

```

# Data cleaning and preprocessing

```{r}
# Cleaning crime data
lines <- strsplit(delitos, 
                  "\n")[[1]]
lines <- lines[lines != "" & !grepl("^\\s+$", 
                                    lines)]
split_lines <- strsplit(lines, 
                        "\\s{2,}")

data <- do.call(rbind, 
                split_lines[7:length(split_lines)])

delitos <- data.frame(data[, c(2, 5)]) 
colnames(delitos) <- c("tipo_penal", "n")


delitosf <- delitos |> 
  mutate(tipo_penal = str_remove(tipo_penal, 
                                 "^\\d+\\.\\s*-?\\s*"),
         year = "2022") |>
  filter(!tipo_penal %in% c("Municipio de Pamplona/Iruña", 
                            "TIPOLOGÍA PENAL", 
                            "I. CRIMINALIDAD CONVENCIONAL",
                            "II. CIBERCRIMINALIDAD (infracciones penales cometidas en/por medio ciber)",
                            "Estafas informáticas", 
                            "Otros ciberdelitos", 
                            "III. TOTAL CRIMINALIDAD"),
         !str_detect(tipo_penal, 
                     "^(5\\.1|5\\.2|7\\.1)\\.-"), 
         !str_detect(tipo_penal, 
                     "[0-9].*[A-Za-z]|[A-Za-z].*[0-9]"),
         !str_detect(n, 
                     "[A-Za-z]"),
         !n == "0") |> 
  mutate(n = as.numeric(str_replace_all(n, 
                                        "[,\\.]", "")),  # Eliminar separadores de miles
         tipo_penal = case_when(
         tipo_penal %in% c("Homicidios dolosos y asesinatos consumados", 
                          "Homicidios dolosos y asesinatos en grado tentativa") ~ "homicidios",
         tipo_penal %in% "Delitos graves y menos graves de lesiones y riña tumultuaria" ~ "lesiones",
         tipo_penal %in% c("Robos con violencia e intimidación", 
                          "Robos con fuerza en domicilios, establecimientos y otras instalaciones", 
                          "Hurtos", 
                          "Sustracciones de vehículos") ~ "robos",
         tipo_penal %in% "Resto de criminalidad CONVENCIONAL" ~ "otros",
         TRUE ~ tipo_penal)) |> 
  group_by(tipo_penal) |> 
  summarise(n = sum(n, 
                    na.rm = TRUE), 
            .groups = 'drop') |> 
  mutate(year = 2022)

```

```{r}
# Reemplazar los valores 98 y 99 por NA. 
pamplona_spss[pamplona_spss == 98 | pamplona_spss == 99 | pamplona_spss == 999] <- NA

```

-   Clean SPSS attributes

```{r}
# Convertir variables etiquetadas a factores con etiquetas descriptivas
pamplona <- pamplona_spss |> 
  mutate(across(where(is.labelled), 
                ~ as_factor(.)))

# Remover atributos innecesarios
remove_unnecessary_attributes <- function(df) {
  for (col in names(df)) {
    attr(df[[col]], 
         "label") <- NULL
    attr(df[[col]], 
         "format.spss") <- NULL
    # Mantener las etiquetas (labels)
  }
  return(df)
}

pamplona <- remove_unnecessary_attributes(pamplona)


# Convertir factores de vuelta a factores con valores numéricos originales
convert_to_numeric_factor <- function(column) {
  if (is.factor(column)) {
    levels(column) <- as.character(1:length(levels(column)))
    factor(as.numeric(column))
  } else {
    column
  }
}

# para trabajar con los valores numricos de las categorias de los factores
pamplona <- pamplona %>%
  mutate(across(where(is.factor), 
                convert_to_numeric_factor))

# si quiero volver a los numericos solo tengo que aplicar la función del prinicpio de este chunk

```

-   Recoding "nacimiento": 1. españa, 2. otros

```{r}
# Convertir los nombres de todas las variables a minúsculas
names(pamplona) <- tolower(names(pamplona))

# Crear y limpiar la nueva variable nP4
pamplona <- pamplona |> 
  mutate(np4 = case_when(
           p4 %in% c(1, 2, 3) ~ 1,
           !is.na(p4_otros) & p4_otros != "-" ~ 2,
           TRUE ~ as.numeric(as.character(p4))  # mantener otros valores P4 si hay
         ),
    p17_otros = na_if(p17_otros, 
                      "-")) |> # convertir "-" en NA en p17_otros
  relocate(np4, 
           .before = p4)

```

## Feature selection

-   Deleting and renaming some variables

```{r}
pamplona <- pamplona |> 
  dplyr::select(-c("estudio", 
                   "registro",
                   "p1",
                   "zona",
                   "p3_cod",
                   "p4",
                   "p4_otros")) |> 
  dplyr::rename(barrio = p1a,
                gender = p2,
                age = p3,
                nationality = np4,
                employment = p20,
                education = p21,
                income = p22)

```

-   Convertir las variables a factores, ordinales y numéricas según
    corresponda

```{r}
# Binary variables
binary_vars <- c("gender", 
                 "p5_1", "p5_2", "p5_3", 
                 "p5_4", "p5_5", "p5_6", 
                 "p5_7", "p5_8",
                 "p6_1", "p6_2", "p6_3",
                 "p8", 
                 "p9", 
                 "p16")

pamplona[binary_vars] <- lapply(pamplona[binary_vars], 
                                as.factor)

# Variables ordinales (trabajando con números)
ordinal_vars <- c("p7_1", "p7_2", "p7_3", 
                  "p7_4", "p7_5", "p7_6", 
                  "p7_7", "p7_8", 
                  "p10_1", "p10_2", "p10_3", 
                  "p10_4", "p10_5", "p10_6", 
                  "p10_7",
                  "p12", 
                  "p15", 
                  "p19", 
                  "education", 
                  "income")

pamplona[ordinal_vars] <- lapply(pamplona[ordinal_vars], 
                                 function(x) factor(x, 
                                                    ordered = TRUE))

# Resto de variables categóricas
categorical_vars <- c("barrio", 
                      "nationality",
                      "p13a", "p13b",
                      "p18", 
                      "employment")

pamplona[categorical_vars] <- lapply(pamplona[categorical_vars], 
                                     as.factor)

# Variables numéricas
numeric_vars <- c("age",
                  "p11_1", "p11_2",
                  "p14")

pamplona[numeric_vars] <- lapply(pamplona[numeric_vars], 
                                 as.numeric)

```

## Missing values

```{r}
# See % of missing values per variable
sapply(pamplona, 
       function(x) sum(is.na(x))*100/nrow(pamplona))

# Remove variables with more than 40% NA
pamplona <- pamplona |> 
  dplyr::select(-c("p17", 
                   "p17_otros"))

```

-   Cart without cross validation (just one variable)

```{r}
vars_cat <- pamplona |> 
  dplyr::select(-c(is.numeric))

# cambiar lo de vars with na
mice_imputed <- data.frame(
  original = vars_cat$p6_3,
  imputed_cart = complete(mice(vars_cat, 
                               m = 2, 
                               method = "cart", 
                               seed = 123))$p6_3)

# Imputation methods: plotting resuls 
variables <- c("original", 
               "imputed_cart")
titles <- c("Original distribution", 
            "Cart-imputed distribution")
colors_fill <- c("skyblue", 
                 "#15ad4f")
colors_border <- c("skyblue3", 
                   "#808080")

# Initialize an empty plot list for the new plots
plots <- list()

# Loop through the updated variables to create plots
for (i in 1:length(variables)) {
  plots[[i]] <- ggplot(mice_imputed, 
                       aes(x = .data[[variables[i]]])) +
    geom_bar(fill = colors_fill[i], 
             color = colors_border[i], 
             position = "identity") +
    ggtitle(titles[i]) +
    theme_classic()
}

# Combine the new set of plots into a grid
plot_grid(plotlist = plots, 
          nrow = 2, 
          ncol = 2)

```

### Cross validation

```{r}
# Function for cross-validation using MICE
cv_mice <- function(data, method, n_folds = 5, seed = 123) {
  set.seed(seed)
  folds <- createFolds(seq_len(nrow(data)), 
                       k = n_folds)
  
  results <- lapply(folds, function(fold) {
    train_data <- data[-fold, ]
    test_data <- data[fold, ]
    
    imputed_train <- mice(train_data, 
                          m = 2, 
                          method = method, 
                          seed = seed)
    complete_train <- complete(imputed_train, 
                               1)  # Use the first imputed dataset
    
    list(train = complete_train, 
         test = test_data)
  })
  
  results
}

# Apply cross-validation for `cart` method
cv_results_cart <- cv_mice(pamplona, 
                           method = "cart")

```

In order to compare the resulting distributions...

1.  Extract imputed values across folds and compare them:

```{r}
# Extract imputed values from each fold
imputed_datasets <- lapply(cv_results_cart, 
                           function(res) res$train)

# Combine imputed data into one data frame for analysis
  # Note: Ensure the imputed datasets have the same structure
combined_imputed_data <- do.call(rbind, 
                                 imputed_datasets)

```

2.  Calculate Variability Across Imputed Values

2.1. For numeric variables: calculate statistics like the mean, standard
deviation, and other relevant metrics for each variable to see how
consistent the imputed values are across different folds.

```{r}
# Analyzing variability for a specific variable
analyze_variability <- function(imputed_data, variable_name) {
  # Extract the specific variable across all imputed datasets
  imputed_values <- combined_imputed_data[[variable_name]]
  
  # Calculate mean and standard deviation across folds
  mean_value <- mean(imputed_values, 
                     na.rm = TRUE)
  sd_value <- sd(imputed_values, 
                 na.rm = TRUE)
  
  list(mean = mean_value, 
       sd = sd_value)
}

# Analyzing variability for the "age" variable as an example
variability_age <- analyze_variability(combined_imputed_data, 
                                       "age")
print(variability_age)

```

2.2. Analyzing variability for categorical variables: frequency tables
and visualizations like bar plots to analyze the consistency and
variability of the imputed values.

```{r}
# Function to calculate and compare frequency distributions
compare_frequency_distributions <- function(original_data, imputed_data, variable_name) {
  # Frequency table for original data
  original_freq <- table(original_data[[variable_name]], 
                         useNA = "ifany")
  original_freq <- original_freq / sum(original_freq)  # Convert to proportions
  
  # Frequency table for imputed data
  imputed_freq <- table(imputed_data[[variable_name]], 
                        useNA = "ifany")
  imputed_freq <- imputed_freq / sum(imputed_freq)  # Convert to proportions
  
  list(original = original_freq, 
       imputed = imputed_freq)
}

# Example for variable "p18" which is categorical
freq_distributions_p18 <- compare_frequency_distributions(pamplona,
                                                          combined_imputed_data, 
                                                          "p18")
print(freq_distributions_p18)

```

3.  Visualize Distribution of Imputed Values to see if there are any
    significant differences across folds.

3.1. Numeric variables

```{r}
# Visualize normalized distribution of imputed values for a specific variable
plot_imputed_distribution_normalized <- function(imputed_data, variable_name) {
  ggplot(imputed_data, aes_string(x = variable_name)) +
    geom_histogram(aes(y = ..density..),  # Use density for normalization
                   binwidth = 1, 
                   fill = "blue", 
                   color = "black", 
                   alpha = 0.7) +
    labs(title = paste("Normalized Distribution of Imputed", 
                       variable_name),
         x = variable_name, 
         y = "Density") +
    theme_minimal()
}

# Plot for the "age" variable as an example
plot_imputed_distribution_normalized(combined_imputed_data, 
                                     "age")

```

```{r}
# Compare original vs imputed data for a variable with normalized values
compare_original_imputed_normalized <- function(original_data, imputed_data, variable_name) {
  original_values <- original_data[[variable_name]]
  imputed_values <- imputed_data[[variable_name]]
  
  # Plot comparison using density for normalization
  ggplot() +
    geom_histogram(aes(x = original_values, y = ..density..), 
                   fill = "skyblue", 
                   alpha = 0.5, 
                   binwidth = 1) +
    geom_histogram(aes(x = imputed_values, y = ..density..), 
                   fill = "orange", 
                   alpha = 0.5, 
                   binwidth = 1) +
    labs(title = paste("Normalized Comparison of Original and Imputed", 
                       variable_name),
         x = variable_name, 
         y = "Density") +
    theme_minimal()
}

# Comparing for the "age" variable as an example
compare_original_imputed_normalized(pamplona, 
                                    combined_imputed_data, 
                                    "age")

```

3.2. Categorical variable

```{r}
# Normalize the frequency counts to proportions
plot_categorical_distribution_normalized <- function(original_data, imputed_data, variable_name) {
  # Frequency tables
  original_freq <- table(original_data[[variable_name]], 
                         useNA = "ifany")
  imputed_freq <- table(imputed_data[[variable_name]], 
                        useNA = "ifany")
  
  # Convert to data frames for ggplot
  original_df <- as.data.frame(prop.table(original_freq))
  imputed_df <- as.data.frame(prop.table(imputed_freq))
  colnames(original_df) <- c("Category", 
                             "Proportion")
  colnames(imputed_df) <- c("Category", 
                            "Proportion")
  
  # Plotting
  ggplot() +
    geom_bar(data = original_df, 
             aes(x = Category, 
                 y = Proportion), 
             stat = "identity", 
             fill = "skyblue", 
             alpha = 0.6) +
    geom_bar(data = imputed_df, 
             aes(x = Category, 
                 y = Proportion), 
             stat = "identity", 
             fill = "orange", 
             alpha = 0.4) +
    labs(title = paste("Normalized Original vs Imputed Data Distribution for",
                       variable_name),
         x = variable_name, 
         y = "Proportion") +
    theme_minimal()
}

# Plot for the "p18" variable
plot_categorical_distribution_normalized(pamplona, 
                                         combined_imputed_data, 
                                         "p18")

```

4.  Imputation without Cross-Validation

```{r}
# Imputing based on cart
pamplonaf <- complete(mice(pamplona, 
                           m = 2, 
                           method = "cart",
                           seed = 123))

```

quería intentar la imputación con cross validation pero no sabía cómo
manejar las 4095 observaciones resultantes (los dos códigos que intenté
están en Thesis.rmd)

# Exploratory analysis

## Descriptive analysis / univariate

```{r}
# Function to generate univariate analysis
univariate_analysis <- function(data) {
  for (col in colnames(data)) {
   cat("Analysis for", col, "\n")
    # Check if the column is numeric
    if (is.numeric(data[[col]])) {
      summary_stats <- summary(data[[col]])
      print(summary_stats)
      
      # Set binwidth based on the variable
      if (col == "age") {
        bin_width <- 5  # Adjust bin width for the 'age' variable
      } else {
        num_unique_values <- length(unique(data[[col]]))
        bin_width <- ifelse(num_unique_values <= 10, 1, 30 / num_unique_values)
      }
      
      # Plot histogram
      p <- ggplot(data, aes_string(x = col)) +
        geom_histogram(binwidth = bin_width, fill = "blue", color = "black") +
        theme_minimal() +
        labs(title = paste("Histogram of", col), x = col, y = "Frequency")
      print(p)
      
    } else if (is.factor(data[[col]]) || is.character(data[[col]])) {
      # Convert character to factor if necessary
      data[[col]] <- as.factor(data[[col]])
      
      # Frequency table
      freq_table <- table(data[[col]])
      print(freq_table)
      
      # Plot bar chart
      p <- ggplot(data, aes_string(x = col)) +
        geom_bar(fill = "blue") +
        theme_minimal() +
        labs(title = paste("Bar Plot of", col), x = col, y = "Count")
      print(p)
      
    } else {
      cat("Variable type not recognized or not supported.\n")
    }
    cat("\n\n")
  }
}

# Call the function
univariate_analysis(pamplonaf)

```

-   Variables related to the *criminality index*.

```{r}
crime_vars <- pamplonaf[, c("p5_1", "p5_2", "p5_3", 
                            "p5_4", "p5_5", "p5_6",
                            "p5_7", "p5_8",
                            "p6_1", "p6_2", "p6_3",
                            "p16")]

univariate_analysis(crime_vars)

```

-   *Perception index*

```{r}
perception_vars <- pamplonaf[, c("p7_1", "p7_2", "p7_3", 
                            "p7_4", "p7_5", "p7_6",
                            "p7_7", "p7_8",
                            "p9", 
                            "p10_1", "p10_2", 
                            "p10_4", "p10_5", "p10_6", 
                            "p11_1", "p11_2", 
                            "p12", 
                            "p14")]

univariate_analysis(perception_vars)

```

-   those related to *self-protection strategies*

```{r}
protections_vars <- pamplonaf[, c("p8",
                                  "p9",
                                  "p10_3", 
                                  "p10_7")]

univariate_analysis(protections_vars)

```

### Data imbalance

```{r}
library(ROSE)

```

## Bivariate analysis

-   correlation analysis for the numeric variables

```{r}
# Select numeric variables
cor_data <- pamplonaf |> 
  dplyr::select(where(is.numeric)) 

# Step 2: Use findCorrelation() to identify highly correlated features
correlation_matrix <- cor(cor_data)
highly_correlated <- findCorrelation(correlation_matrix, 
                                     cutoff = 0.70, 
                                     exact = FALSE)

# Step 3: Remove highly correlated features from the dataset
selected_features <- cor_data[, -highly_correlated]

# Getting the names of the selected features
selected_features <- names(selected_features)

# New sample dataset
data_f <- pamplonaf |> 
  dplyr::select(selected_features, 
                p6_2)

# Fitting a logistic regression model
linear_model <- glm(p6_2 ~ ., data = data_f, family = binomial)
summary(linear_model)

```

-   contingency tables and chi-square tests as almost all the variables
    are categorical

```{r}
# Function to generate contingency tables and perform chi-square tests
bivariate_analysis <- function(df, var1, var2) {
  # Create contingency table
  contingency_table <- df |> 
    tabyl(!!sym(var1), !!sym(var2)) |> 
    adorn_percentages("col") |> 
    adorn_pct_formatting(digits = 1) |> 
    adorn_ns()
  
  # Perform chi-square test
  chi_test <- chisq.test(table(df[[var1]], 
                               df[[var2]]))
  
  # Return results
  list(
    var1 = var1,
    var2 = var2,
    contingency_table = contingency_table,
    chi_square_test = chi_test
  )
}

# Define the list of sociodemographic variables and the variable of interest
sociodemographic_vars <- c("barrio", 
                           "gender",  
                           "education",
                           "employment",
                           "nationality", 
                           "income")

# Store the results in a list
results_list <- lapply(sociodemographic_vars, function(var) {
  bivariate_analysis(pamplonaf, var, "p5_1")
})

# Display results in separate "screens"
for (result in results_list) {
  cat("====================================================\n")
  cat("Analysis between", result$var1, "and", result$var2, "\n")
  cat("====================================================\n\n")
  
  cat("Contingency Table:\n")
  print(result$contingency_table)
  cat("\n")
  
  cat("Chi-Square Test Results:\n")
  print(result$chi_square_test)
  cat("\n\n")
  
  # Adding a pause for clarity if running interactively
  # readline(prompt = "Press [Enter] to continue to the next analysis...")
}

```

-   t test analysis:

```{r}
# Example for visual inspection and normality test
# Q-Q plot: Deviations from the line, especially in the tails, indicate departures from normality.
qqnorm(pamplonaf$p11_1)

# Histogram
hist(pamplonaf$p11_1, breaks = 30, main = "Histogram of p11_1", xlab = "p11_1")

# Shapiro-Wilk test
  # h0: data is normally distributed. 
  # p-value > 0.05: data is normally distributed.
  # p-value ≤ 0.05: Reject H0, data is not normally distributed.
shapiro.test(pamplonaf$p11_1)

```

```{r}
# Levene's test. H0: variances are equal.
  # p-value > 0.05: homogeneity of variances.
  # p-value ≤ 0.05: heterogeneity of variances.

library(car)
leveneTest(p11_1 ~ gender, data = pamplonaf)

```

```{r}
# Load necessary libraries
library(dplyr)
library(janitor)
library(stats)

# Function to perform t-test or ANOVA
bivariate_numeric_analysis <- function(df, numeric_var, categorical_var) {
  # Check the number of levels in the categorical variable
  n_levels <- length(unique(df[[categorical_var]]))
  
  # Choose test based on the number of levels
  if (n_levels == 2) {
    # Perform t-test
    test_result <- t.test(df[[numeric_var]] ~ df[[categorical_var]], 
                          data = df)
    test_type <- "T-test"
  } else {
    # Perform ANOVA
    test_result <- aov(df[[numeric_var]] ~ df[[categorical_var]], 
                       data = df)
    test_type <- "ANOVA"
  }
  
  # Return results
  list(
    numeric_var = numeric_var,
    categorical_var = categorical_var,
    test_type = test_type,
    test_result = test_result
  )
}

# Define the list of sociodemographic variables
sociodemographic_vars <- c("barrio", 
                           "gender", 
                           "education", 
                           "employment", 
                           "nationality", 
                           "income")

# Numeric variables to analyze
numeric_vars <- c("p11_1", "p11_2",
                  "p14")

# Store the results in a list
results_list <- lapply(sociodemographic_vars, function(cat_var) {
  lapply(numeric_vars, function(num_var) {
    bivariate_numeric_analysis(pamplonaf, num_var, cat_var)
  })
})

# Display results in separate "screens"
for (result_set in results_list) {
  for (result in result_set) {
    cat("====================================================\n")
    cat("Analysis between", result$numeric_var, "and", result$categorical_var, "\n")
    cat("Test Type:", result$test_type, "\n")
    cat("====================================================\n\n")
    
    if (result$test_type == "T-test") {
      cat("T-test Results:\n")
      cat("t-statistic:", result$test_result$statistic, "\n")
      cat("Degrees of Freedom:", result$test_result$parameter, "\n")
      cat("p-value:", result$test_result$p.value, "\n")
      cat("Confidence Interval:", result$test_result$conf.int, "\n")
      cat("Mean of Groups:", result$test_result$estimate, "\n")
    } else if (result$test_type == "ANOVA") {
      cat("ANOVA Results:\n")
      print(summary(result$test_result))
    }
    
    cat("\n\n")
    # Adding a pause for clarity if running interactively
    # readline(prompt = "Press [Enter] to continue to the next analysis...")
  }
}

```

# UNSUPERVISED MACHINE LEARNING

## Principal Component Analysis (PCA)

-   P10_4,5,6 -\> cameras

```{r}
# Convert factors or characters to numeric
perception_vars$p10_1 <- as.numeric(as.character(perception_vars$p10_1))
perception_vars$p10_2 <- as.numeric(as.character(perception_vars$p10_2))

perception_vars$p10_4 <- as.numeric(as.character(perception_vars$p10_4))
perception_vars$p10_5 <- as.numeric(as.character(perception_vars$p10_5))
perception_vars$p10_6 <- as.numeric(as.character(perception_vars$p10_6))

# Normalizamos p10_6 para que los valores más altos sean negativos (indicando una percepción negativa)
perception_vars$normalized_p10_6 <- 5 - perception_vars$p10_6

# Creamos la nueva variable compuesta. antes era indice_percepcion_camaras
perception_vars$cam_index <- (perception_vars$p10_4 + perception_vars$p10_5) - perception_vars$normalized_p10_6

# Calculamos el valor mínimo y máximo de la nueva variable compuesta
min_val <- min(perception_vars$cam_index, 
               na.rm = TRUE)
max_val <- max(perception_vars$cam_index, 
               na.rm = TRUE)

# Normalización min-max para ajustar el rango a [1, 4]
perception_vars$cam_index <- 1 + (perception_vars$cam_index - min_val) * (3 / (max_val - min_val))

# reondeo a enteros
perception_vars$cam_index <- round(perception_vars$cam_index)

# Inspeccionamos la nueva variable normalizada
table(perception_vars$cam_index)

```

La nueva variable compuesta cam_index tiene un rango de 1 a 4, donde los
valores representan la percepción general de las personas sobre las
cámaras de seguridad en términos de su adecuación, mejora de seguridad
ciudadana y posible invasión de la intimidad. Dado que la escala se
deriva de la combinación de varias percepciones, la interpretación de
los extremos es la siguiente

1.  Percepción muy negativa o preocupación sobre las cámaras de
    seguridad.

2.  Percepción algo negativa.

3.  Percepción algo positiva.

4.  Percepción muy positiva

-   P10_1,2 -\> seg global nocturna

```{r}
# Combinamos p10_1 y p10_2. antes era seguridad_global_noche
perception_vars$night_security <- perception_vars$p10_1 + perception_vars$p10_2

# Calculamos el valor mínimo y máximo de la nueva variable
min_val_seguridad <- min(perception_vars$seguridad_global_noche,
                         na.rm = TRUE)
max_val_seguridad <- max(perception_vars$seguridad_global_noche, 
                         na.rm = TRUE)

# Normalización min-max para ajustar el rango a [1, 4]
perception_vars$night_security <- 1 + (perception_vars$seguridad_global_noche - min_val_seguridad) * (3 / (max_val_seguridad - min_val_seguridad))

# Redondeamos los valores normalizados a enteros
perception_vars$night_security <- round(perception_vars$night_security)

# Inspeccionamos la nueva distribución de frecuencias
table(perception_vars$night_security)

```

-   p11_1,2 -\> seg global general

```{r}
perception_vars$global_security <- rowMeans(perception_vars[, c("p11_1", "p11_2")], 
                                             na.rm = TRUE)

# Redondeamos los valores normalizados a enteros
perception_vars$global_security <- round(perception_vars$global_security)

# Inspeccionamos la nueva variable
table(perception_vars$global_security)

```

```{r}
perception_vars <- perception_vars |> 
  dplyr::select(-c("p10_1", "p10_2",
                   "p10_4", "p10_5", "p10_6",
                   "p11_1", "p11_2",
                   "normalized_p10_6", 
                   "p14"))
```

-   Creating dummies

```{r}
# List of columns to be converted to factors
factor_columns <- c('p7_2', 'p7_3', 'p7_4', 
                    'p7_5', 'p7_6', 'p7_7', 
                    'p7_8', 
                    'p12')

# Convert selected columns to factors
perception_vars[factor_columns] <- lapply(perception_vars[factor_columns],
                                          as.factor)


options(contrasts = c("contr.treatment", "contr.treatment"))

# Dummy encoding, dropping the first category as the reference
percept_dummy <- model.matrix(~ . - 1, 
                              data = perception_vars)

# Convert the result to a data frame
percept_dummy <- as.data.frame(percept_dummy)

# Normalizing the data
df_normalized <- scale(percept_dummy)

```

```{r}
# Calculate the correlation matrix
correlation_matrix <- cor(percept_dummy)

# Set a threshold for correlation; features with absolute correlation above this threshold are considered redundant
correlation_threshold <- 0.70  # Adjust this threshold as needed

# Find highly correlated features
highly_correlated <- findCorrelation(correlation_matrix, 
                                     cutoff = correlation_threshold)

# Remove highly correlated features
df_reduced <- percept_dummy[, -highly_correlated]

```

```{r}
# Perform PCA
pca_result <- prcomp(df_reduced, 
                     center = TRUE, 
                     scale. = TRUE)

# View the proportion of variance explained by each principal component
summary(pca_result)

```

## Clustering

# SUPERVISED MACHINE LEARNING

## Classification

## Advanced regressions

# FINAL PREDICTIONS
